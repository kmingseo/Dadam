import React, { useEffect, useState, useRef, useMemo } from "react";
import {
    View,
    Text,
    TouchableOpacity,
    Image,
    ActivityIndicator,
    Alert,
    Platform,
    PermissionsAndroid,
} from "react-native";
import axios from "axios";
import AudioRecorderPlayer, {
    AudioSet,
    AudioEncoderAndroidType,
    AudioSourceAndroidType,
    OutputFormatAndroidType,
    AVEncoderAudioQualityIOSType,
} from "react-native-audio-recorder-player";

export interface WordType {
    id: number | null;
    targetWord: string;
    imageUrl: string;
    languageCode: string;
}

export interface ResultType {
    transcribedText: string;
    score: number;
    targetWord: string;
    imageUrl: string;
}

interface SpeakingEvaluatorProps {
    type: "consonant" | "vowel" | "syllable" | "word" | "sentence";
}

const BASE_URL = "http://10.0.2.2:8080"; // ì—ë®¬ë ˆì´í„°ì—ì„œ localhost ëŒ€ì‹  10.0.2.2 ì‚¬ìš©

const LANGUAGES = [
    { code: "ko", name: "í•œêµ­ì–´" },
    { code: "ja", name: "ì¼ë³¸ì–´" },
    { code: "zh", name: "ì¤‘êµ­ì–´" },
    { code: "vi", name: "ë² íŠ¸ë‚¨ì–´" },
];

const SpeakingEvaluator: React.FC<SpeakingEvaluatorProps> = ({ type }) => {
    const audioRecorderPlayerRef = useRef<any>(null);

    const [wordList, setWordList] = useState<WordType[]>([]);
    const [selectedLanguage, setSelectedLanguage] = useState(LANGUAGES[0].code);
    const [currentWordIndex, setCurrentWordIndex] = useState(0);
    const [currentWord, setCurrentWord] = useState<WordType>({
        id: null,
        targetWord: "",
        imageUrl: "",
        languageCode: "",
    });
    const [recordedFilePath, setRecordedFilePath] = useState<string>("");
    const [isRecording, setIsRecording] = useState(false);
    const [isLoading, setIsLoading] = useState(false);
    const [evaluationResult, setEvaluationResult] = useState<ResultType>({
        transcribedText: "",
        score: 0,
        targetWord: "",
        imageUrl: "",
    });
    const [statusMessage, setStatusMessage] = useState("ë…¹ìŒ ë²„íŠ¼ì„ ëˆŒëŸ¬ ì‹œì‘í•˜ì„¸ìš”.");

    const filteredWordList = useMemo(
        () => wordList.filter((w) => w.languageCode === selectedLanguage),
        [wordList, selectedLanguage]
    );

    useEffect(() => {
        fetchWordList();

        audioRecorderPlayerRef.current = new AudioRecorderPlayer();

        return () => {
            audioRecorderPlayerRef.current?.stopRecorder();
            audioRecorderPlayerRef.current?.removeRecordBackListener();
        };
    }, []);

    useEffect(() => {
        if (filteredWordList.length === 0) return;

        setCurrentWord(filteredWordList[currentWordIndex]);
        setEvaluationResult({
            transcribedText: "",
            score: 0,
            targetWord: "",
            imageUrl: "",
        });
        setStatusMessage(`"${filteredWordList[currentWordIndex].targetWord}" ë°œìŒí•˜ê¸°`);
    }, [filteredWordList, currentWordIndex]);

    // ğŸ”¹ ìˆ˜ì •ëœ fetchWordList

    const fetchWordList = async () => {
        try {
            const res = await axios.get(`${BASE_URL}/api/${type}s`); // typeì— ë”°ë¼ API í˜¸ì¶œ
            console.log("ë°±ì—”ë“œ ì‘ë‹µ:", res.data);

            const mapped = res.data.map((item: any) => {
                // itemì´ Word ê°ì²´ì¸ì§€, ë¬¸ìì—´ ë°°ì—´ì¸ì§€ êµ¬ë¶„
                if (typeof item === "string") {
                    // ììŒ/ëª¨ìŒ/ìŒì ˆ
                    return {
                        id: null,
                        targetWord: item,
                        imageUrl: "",   // ì´ë¯¸ì§€ ì—†ìŒ
                        languageCode: "ko",
                    };
                } else {
                    // ë‹¨ì–´/ë¬¸ì¥
                    return {
                        id: item.id ?? null,
                        targetWord: item.text ?? "",
                        imageUrl: item.imageUrl ?? "",
                        languageCode: item.language ?? "ko",
                    };
                }
            });

            setWordList(mapped);
        } catch (e) {
            console.error("ë‹¨ì–´ ëª©ë¡ ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨:", e);
            Alert.alert("ì—ëŸ¬", "ë‹¨ì–´ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.");
        }
    };

    const requestRecordingPermission = async () => {
        if (Platform.OS === "android") {
            try {
                const granted = await PermissionsAndroid.requestMultiple([
                    PermissionsAndroid.PERMISSIONS.WRITE_EXTERNAL_STORAGE,
                    PermissionsAndroid.PERMISSIONS.RECORD_AUDIO,
                ]);
                const recordGranted =
                    granted["android.permission.RECORD_AUDIO"] ===
                    PermissionsAndroid.RESULTS.GRANTED;
                const storageGranted =
                    granted["android.permission.WRITE_EXTERNAL_STORAGE"] ===
                    PermissionsAndroid.RESULTS.GRANTED;

                if (!recordGranted || !storageGranted) {
                    Alert.alert("ê¶Œí•œ í•„ìš”", "ë…¹ìŒ ë° ì €ì¥ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤.");
                    return false;
                }
            } catch (err) {
                console.warn(err);
                return false;
            }
        }
        return true;
    };

    const startRecording = async () => {
        const hasPermission = await requestRecordingPermission();
        if (!hasPermission) return;

        try {
            const audioSet: AudioSet = {
                AudioEncoderAndroid: AudioEncoderAndroidType.AAC,
                AudioSourceAndroid: AudioSourceAndroidType.MIC,
                AVEncoderAudioQualityKeyIOS: AVEncoderAudioQualityIOSType.high,
                AVNumberOfChannelsKeyIOS: 2,
                AVSampleRateKeyIOS: 44100,
                OutputFormatAndroid: OutputFormatAndroidType.MPEG_4,
            };

            const path = Platform.select({
                ios: "hello.m4a",
                android: "/sdcard/hello.mp4",
            });

            if (!path) {
                Alert.alert("ë…¹ìŒ ì˜¤ë¥˜", "ì§€ì›ë˜ì§€ ì•ŠëŠ” í”Œë«í¼ ê²½ë¡œ");
                return;
            }

            const uri = await audioRecorderPlayerRef.current.startRecorder(path, audioSet);
            audioRecorderPlayerRef.current.addRecordBackListener((e: any) => {
                console.log("Record Time:", e.currentPosition);
            });

            setIsRecording(true);
            setStatusMessage("ğŸ”´ ë…¹ìŒ ì¤‘...");
            setRecordedFilePath(uri);
        } catch (e) {
            console.error("ë…¹ìŒ ì‹œì‘ ì˜¤ë¥˜:", e);
            Alert.alert("ë…¹ìŒ ì˜¤ë¥˜", "ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨");
            setIsRecording(false);
        }
    };

    const stopRecording = async () => {
        try {
            const filePath = await audioRecorderPlayerRef.current.stopRecorder();
            audioRecorderPlayerRef.current.removeRecordBackListener();

            setIsRecording(false);
            setRecordedFilePath(filePath);
            setStatusMessage("ë…¹ìŒ ì™„ë£Œ! í‰ê°€ ìš”ì²­ ì¤‘...");
            uploadRecording(filePath);
        } catch (e) {
            Alert.alert("ë…¹ìŒ ì˜¤ë¥˜", "ë…¹ìŒ ì¤‘ì§€ ì‹¤íŒ¨");
        }
    };

    const uploadRecording = async (filePath: string) => {
        if (!currentWord.id) return;

        setIsLoading(true);
        try {
            const fileUri =
                Platform.OS === "android" && filePath.startsWith("file://")
                    ? filePath.substring(7)
                    : filePath;

            const formData = new FormData();
            formData.append("audio", {
                uri: fileUri,
                name: "recording.mp4",
                type: "audio/mp4",
            });
            formData.append("wordId", currentWord.id.toString());

            const res = await axios.post(`${BASE_URL}/api/evaluate-speech`, formData, {
                headers: { "Content-Type": "multipart/form-data" },
            });

            const data: ResultType = res.data;
            setEvaluationResult(data);
            setStatusMessage(`í‰ê°€ ì™„ë£Œ! ì ìˆ˜: ${data.score}`);

            if (data.score < 80) Alert.alert("ì•„ì‰½ìŠµë‹ˆë‹¤", `${data.score}ì ì…ë‹ˆë‹¤.`);
        } catch (e) {
            console.error("í‰ê°€ ìš”ì²­ ì‹¤íŒ¨:", e);
            Alert.alert("ì˜¤ë¥˜", "í‰ê°€ ìš”ì²­ ì‹¤íŒ¨. ì„œë²„ ìƒíƒœë¥¼ í™•ì¸í•˜ì„¸ìš”.");
        } finally {
            setIsLoading(false);
        }
    };

    const goNext = () => {
        if (evaluationResult.score < 80) {
            Alert.alert("ë‹¤ì‹œ ì‹œë„", "80ì  ì´ìƒ ë°›ì•„ì•¼ ë„˜ì–´ê°ˆ ìˆ˜ ìˆì–´ìš”.");
            return;
        }
        if (currentWordIndex >= filteredWordList.length - 1) {
            Alert.alert("ì™„ë£Œ", "ëª¨ë“  ë‹¨ì–´ë¥¼ í‰ê°€í–ˆìŠµë‹ˆë‹¤!");
            return;
        }
        setCurrentWordIndex((prev) => prev + 1);
    };

    const displayedImage = evaluationResult.imageUrl || currentWord.imageUrl;
    const canGoNext = evaluationResult.score >= 80;

    return (
        <View style={{ flex: 1, alignItems: "center", paddingTop: 40 }}>
            <Text style={{ fontSize: 22, fontWeight: "bold", marginBottom: 20 }}>
                Speaking Practice â€” {type}
            </Text>

            <Text style={{ fontSize: 18, marginBottom: 10 }}>{statusMessage}</Text>

            {displayedImage && (
                <Image
                    source={{ uri: displayedImage }}
                    style={{ width: 200, height: 200, borderRadius: 12, marginBottom: 20 }}
                />
            )}

            <Text style={{ fontSize: 28, fontWeight: "600", marginBottom: 20 }}>
                {currentWord.targetWord}
            </Text>

            {!isRecording ? (
                <TouchableOpacity
                    onPress={startRecording}
                    disabled={isLoading}
                    style={{
                        padding: 16,
                        backgroundColor: isLoading ? "#9ca3af" : "#2563eb",
                        borderRadius: 12,
                        marginBottom: 16,
                    }}
                >
                    <Text style={{ color: "white", fontSize: 18 }}>ğŸ™ï¸ ë…¹ìŒ ì‹œì‘</Text>
                </TouchableOpacity>
            ) : (
                <TouchableOpacity
                    onPress={stopRecording}
                    style={{
                        padding: 16,
                        backgroundColor: "#dc2626",
                        borderRadius: 12,
                        marginBottom: 16,
                    }}
                >
                    <Text style={{ color: "white", fontSize: 18 }}>â¹ï¸ ë…¹ìŒ ì¤‘ì§€</Text>
                </TouchableOpacity>
            )}

            {isLoading && <ActivityIndicator size="large" style={{ marginBottom: 20 }} />}

            {evaluationResult.score > 0 && (
                <View style={{ alignItems: "center", marginTop: 20 }}>
                    <Text style={{ fontSize: 20, marginBottom: 10 }}>
                        ì ìˆ˜: {evaluationResult.score}ì 
                    </Text>
                    <Text style={{ fontSize: 16 }}>
                        ì¸ì‹ëœ í…ìŠ¤íŠ¸: {evaluationResult.transcribedText}
                    </Text>
                </View>
            )}

            <TouchableOpacity
                disabled={!canGoNext || isLoading}
                onPress={goNext}
                style={{
                    opacity: !canGoNext || isLoading ? 0.5 : 1,
                    marginTop: 30,
                    padding: 14,
                    backgroundColor: "#16a34a",
                    borderRadius: 12,
                }}
            >
                <Text style={{ color: "white", fontSize: 18 }}>ë‹¤ìŒ ë‹¨ì–´ â¡ï¸</Text>
            </TouchableOpacity>
        </View>
    );
};

export default SpeakingEvaluator;
